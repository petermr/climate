<?xml version="1.0" encoding="UTF-8"?>
<p id="Par18">The fact that studies with small samples reported substantially higher average effect sizes than papers with larger samples (
 <italic>d</italic> = −0.335 vs. 
 <italic>d</italic> ≤ −0.141, respectively) suggests small-study bias
 <sup>
  <xref ref-type="bibr" rid="CR30">30</xref>
 </sup>. Figure 
 <xref rid="Fig2" ref-type="fig">2</xref> visually displays the relationship between estimate precision (based on standard errors) and the magnitude of the effect reported. Estimates with lower standard errors tend to cluster around a zero effect. This visual examination is statistically confirmed by the Egger’s test
 <sup>
  <xref ref-type="bibr" rid="CR31">31</xref>
 </sup>, with a significant negative slope (
 <italic>B</italic> = −0.0321, 
 <italic>p</italic> &lt; 0.001) indicating that the smaller the sample, the stronger the effect size reported. This result would not pose a problem if small sample studies were reporting low between-study variance (
 <italic>I</italic>
 <sup>2</sup> &lt; 40%). However, only the large sample studies (
 <italic>N</italic> ≥ 500 per group) are estimating precise effect sizes for their population (
 <italic>I</italic>
 <sup>2</sup> = 25.6% ns).
</p>
