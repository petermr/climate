<?xml version="1.0" encoding="UTF-8"?>
<p id="Par5">The relative effectiveness of such interventions, nevertheless, has not been carefully evaluated. There have been several attempts to summarise evidence on this topic, including quantitative meta-analyses
 <sup>
  <xref ref-type="bibr" rid="CR10">10</xref>â€“
  <xref ref-type="bibr" rid="CR14">14</xref>
 </sup>, but this previous work suffers from substantive limitations. These limitations include estimating behavioural effects from self-reported beliefs, attitudes or intentions, as well as combining estimates from observational and experimental study designs, in addition to mixing artificial lab evidence with real world behaviour. Such limitations pose severe problems for impact evaluation. On the one hand, estimates from quasi or non-experimental studies tend to be larger and are more likely to be significant by comparison to estimates based on more stringent experimental designs
 <sup>
  <xref ref-type="bibr" rid="CR15">15</xref>
 </sup>. On the other hand, the gap between attitudes and intentions reported in the lab, and real-world behaviour is well-documented
 <sup>
  <xref ref-type="bibr" rid="CR16">16</xref>
 </sup>, and similarly, the impact of interventions on self-reported measures tends to be higher and more likely to reach statistical significance compared to effects on tangible behaviour
 <sup>
  <xref ref-type="bibr" rid="CR17">17</xref>
 </sup>. Such biasing effects should not be underestimated. These may induce the perception that most common interventions are effective, erroneously leading scholars and policy makers to use the available (possibly inflated) estimates as the basis for important predictions for climate change mitigation
 <sup>
  <xref ref-type="bibr" rid="CR18">18</xref>
 </sup>.
</p>
