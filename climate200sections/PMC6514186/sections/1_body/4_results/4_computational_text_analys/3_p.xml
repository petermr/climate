<?xml version="1.0" encoding="UTF-8"?>
<p>The 532 translated text units served as the main text corpus. For analyses, texts were further processed using standard procedures such as lowercase conversion, deletion of stopwords, punctuation, and numbers, and stemming (
 <xref rid="B26" ref-type="bibr">Grimmer and Stewart, 2013</xref>; 
 <xref rid="B73" ref-type="bibr">Welbers et al., 2017</xref>). According to the 
 <italic>bag-of-words</italic> assumption, a text is viewed as a collection of words regardless of sequence and linguistic structures (
 <xref rid="B45" ref-type="bibr">Lucas et al., 2015</xref>); although this omits information, pertinent research has shown that this approach is able to capture much of the meaningful content. This reduction can be understood as a kind of normalization of texts, condensing natural text to its basic lexical content. For the reduced texts, mean word number was 
 <italic>M</italic> = 40.9 per recollection (
 <italic>SD</italic> = 36.8, 
 <italic>Median</italic> = 31), with little difference between Stage 1 (
 <italic>M</italic> = 41.5) and Stage 2 (
 <italic>M</italic> = 40.3). After normalization, 12 text units had zero words and were excluded from the following analyses.
</p>
