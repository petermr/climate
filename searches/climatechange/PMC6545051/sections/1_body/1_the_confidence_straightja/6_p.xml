<?xml version="1.0" encoding="UTF-8"?>
<p class="p">There is always a trade-off to be made between reliability and informativeness [
 <xref rid="RSPA20190013C19" ref-type="bibr" class="xref">19</xref>]. Yet, a focus on reliability, guarding preferentially against type 1 errors (false positives, i.e. false alarms), increases the likelihood of type 2 errors (false negatives, i.e. missed warnings). It follows that much as though climate science might strive to be value free, it cannot be: the way in which climate information is constructed has ethical implications [
 <xref rid="RSPA20190013C20" ref-type="bibr" class="xref">20</xref>]. Lloyd &amp; Oreskes [
 <xref rid="RSPA20190013C20" ref-type="bibr" class="xref">20</xref>] raise the important question of why, in climate science, it has become normative that scientific rigour is associated with a focus on reliability. They point out that the decision on whether to preferentially guard against type 1 or type 2 errors is not a scientific one, but one of values. For example, in deciding whether to bring a new drug to market, one assesses both the drug's efficacy (guarding against type 1 errors) and whether it has any unwanted side effects (guarding against type 2 errors). Similarly, in deciding whether to issue an evacuation order for a city in the face of a forecasted storm, a balance of concern between type 1 and type 2 errors will be considered. Thus, there is nothing unscientific about seeking to guard against type 2 errors.
</p>
